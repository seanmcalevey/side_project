{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru_e512_g256_g256_d1024_(30steps)",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPs73OiWnbDVhut5o94eiDn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanmcalevey/side_project/blob/master/gru_e512_g256_g256_d1024_(30steps).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKkKtD12Ejha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! pip install -U tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giT-5ASe_C8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E32KxzGEkz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a2991ff-3f9f-4738-ae42-455653d3b1f5"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgLkgP6__HIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "88050783-0921-4dc5-91c5-4c861d6d7e20"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK-iruJ0_j67",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "10ad80e2-f96a-4c43-e5fc-4c60a12de612"
      },
      "source": [
        "master_df = pd.read_csv('/content/drive/My Drive/Consumer_Complaints.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,6,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSUqa1mmTF4N",
        "colab_type": "text"
      },
      "source": [
        "## Sample and Process Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx6xIRwk_w3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proc_df = master_df.dropna(subset=['Consumer complaint narrative']).sample(20000, random_state=55)\n",
        "\n",
        "clean = [re.sub('[^A-Za-z.,\\s\\']', '', nar) for nar in proc_df['Consumer complaint narrative']]\n",
        "\n",
        "split_word_nars = [nar.split() for nar in clean]\n",
        "\n",
        "\"\"\"Contractions Import\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive')\n",
        "from english_contractions import replace_contraction\n",
        "\n",
        "\"\"\"End Contraction Import\"\"\"\n",
        "\n",
        "new_words = []\n",
        "\n",
        "for nar in split_word_nars:\n",
        "\n",
        "  nar_words = []\n",
        "\n",
        "  for word in nar:\n",
        "\n",
        "    if re.search('\\w+[.]', word):\n",
        "\n",
        "      splitted = word.split('.')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append('.')\n",
        "    \n",
        "    elif re.search('\\w+[,]', word):\n",
        "      \n",
        "      splitted = word.split(',')\n",
        "\n",
        "      tmp_words = replace_contraction(splitted[0].lower())\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "      nar_words.append(',')\n",
        "    \n",
        "    elif re.match('[.]', word):\n",
        "      \n",
        "      placeholder = 1\n",
        "    \n",
        "    else:\n",
        "\n",
        "      tmp_words = replace_contraction(word)\n",
        "\n",
        "      for w in tmp_words.split():\n",
        "\n",
        "        nar_words.append(w)\n",
        "\n",
        "  new_words.append(nar_words)\n",
        "\n",
        "words = [word for words in new_words for word in words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9cKM19tTLJi",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAfI4Onw_3ir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b8cd23a6-baa3-4efc-b5bb-381156c0eaee"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "num_words = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_words, filters='')\n",
        "\n",
        "tokenizer.fit_on_texts(words)\n",
        "\n",
        "encoded = tokenizer.texts_to_sequences(words)\n",
        "\n",
        "max_id = num_words\n",
        "\n",
        "dataset_size = tokenizer.document_count\n",
        "\n",
        "flat_encoded = [enc for encoder in encoded for enc in encoder]\n",
        "\n",
        "print(max_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5-GJJrXTOdM",
        "colab_type": "text"
      },
      "source": [
        "## Split Train and Val Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZZyo8gh_6Lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = dataset_size * 90 // 100\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices(flat_encoded[:train_size])\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(flat_encoded[train_size:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YBzSUUkTQQO",
        "colab_type": "text"
      },
      "source": [
        "## Batch and Prepare Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EWS2Mzb_8A0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "\n",
        "n_steps = 30\n",
        "\n",
        "window_length = n_steps + 1\n",
        "\n",
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\n",
        "\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "\n",
        "# dataset = dataset.map(lambda X_batch, y_batch: (tf.one_hot(X_batch, depth=max_id), y_batch))\n",
        "\n",
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7hNzKoaTT_t",
        "colab_type": "text"
      },
      "source": [
        "## Batch and Prepare Val Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ11iYm8__B2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = val_dataset.window(window_length, shift=1, drop_remainder=True)\n",
        "\n",
        "val_dataset = val_dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "val_dataset = val_dataset.shuffle(10000).batch(batch_size)\n",
        "\n",
        "val_dataset = val_dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
        "\n",
        "# val_dataset = val_dataset.map(lambda X_batch, y_batch: (tf.one_hot(X_batch, depth=max_id), y_batch))\n",
        "\n",
        "val_dataset = val_dataset.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfXB6GSUOWqO",
        "colab_type": "text"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW1kZCD4zqlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "637f8696-65c8-4f7f-e6c2-76e327ef5a5a"
      },
      "source": [
        "# Early Stopping\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopper = EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
        "\n",
        "# Checkpoing Model Weights\n",
        "\n",
        "import os\n",
        "\n",
        "checkpoint_path = 'checkpoints/cp-{epoch:04d}.ckpt'\n",
        "\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    period=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHMHrt4zTWze",
        "colab_type": "text"
      },
      "source": [
        "## Identify Last Epoch Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJrFnmyElWXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "\n",
        "latest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mVvv3J4ThZi",
        "colab_type": "text"
      },
      "source": [
        "## Size of Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oESe7TX5ABaF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43d39ff4-edcd-4af5-cea7-b5c2bf258e71"
      },
      "source": [
        "steps_per_epoch = train_size // batch_size\n",
        "\n",
        "steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14155"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "902P8Fq3TkTZ",
        "colab_type": "text"
      },
      "source": [
        "## Build and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGHvprrVADSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "31b6449c-b85e-4724-a41c-fe741c9b1a6c"
      },
      "source": [
        "adam = tf.keras.optimizers.Adam()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(max_id, 512, input_shape=[None]),\n",
        "                                    tf.keras.layers.GRU(256, return_sequences=True,\n",
        "                                                        dropout=0.5, recurrent_dropout=0.5),\n",
        "                                    tf.keras.layers.GRU(256, return_sequences=True,\n",
        "                                                        dropout=0.5, recurrent_dropout=0.5),\n",
        "                                    tf.keras.layers.Dropout(0.5),\n",
        "                                    tf.keras.layers.Dense(1024, activation='sigmoid'),\n",
        "                                    tf.keras.layers.Dense(max_id, activation='softmax')])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# model.load_weights(latest)\n",
        "\n",
        "model.fit(dataset, epochs=2, validation_data=val_dataset, callbacks=[early_stopper, checkpoint_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "  14156/Unknown - 3239s 229ms/step - loss: 3.9655 - accuracy: 0.2480\n",
            "Epoch 00001: saving model to checkpoints/cp-0001.ckpt\n",
            "14156/14156 [==============================] - 3347s 236ms/step - loss: 3.9655 - accuracy: 0.2480 - val_loss: 4.4203 - val_accuracy: 0.2411\n",
            "Epoch 2/2\n",
            "14155/14156 [============================>.] - ETA: 0s - loss: 3.7341 - accuracy: 0.2712\n",
            "Epoch 00002: saving model to checkpoints/cp-0002.ckpt\n",
            "14156/14156 [==============================] - 3326s 235ms/step - loss: 3.7340 - accuracy: 0.2712 - val_loss: 4.3053 - val_accuracy: 0.2488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7d1010f208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkbiSXd7kWu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "069152c5-6d02-49a8-b08c-5cca9562f40f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_30 (GRU)                 (None, None, 256)         7878144   \n",
            "_________________________________________________________________\n",
            "gru_31 (GRU)                 (None, None, 256)         394752    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, None, 256)         65792     \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, None, 10000)       2570000   \n",
            "=================================================================\n",
            "Total params: 10,908,688\n",
            "Trainable params: 10,908,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha6YqnWwc4Gi",
        "colab_type": "text"
      },
      "source": [
        "## Save the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-aAO0TvdTTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_path = '/content/drive/'\n",
        "\n",
        "file_path = 'My Drive/saved_keras_rnns/'\n",
        "\n",
        "name = 'gru_1002.h5'\n",
        "\n",
        "model.save(drive_path + file_path + name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TKPz18_A2k7",
        "colab_type": "text"
      },
      "source": [
        "## Save the Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpny2hXlA4W8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "tokenizer_name = 'tok_gru_1002.pkl'\n",
        "\n",
        "pickle.dump(tokenizer, open(drive_path + file_path + tokenizer_name, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfRRUk4EywYL",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpsZDDXMePG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = 'gru_30_steps.h5'\n",
        "\n",
        "new_model = keras.models.load_model(drive_path + file_path + name)\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_DB73L-708y",
        "colab_type": "text"
      },
      "source": [
        "## Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaW0U15tAhii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_clean(text):\n",
        "\n",
        "  splits = text.split(' . ')[:-1]\n",
        "\n",
        "  new_splits = []\n",
        "\n",
        "  for split in splits[1:]:\n",
        "\n",
        "    word_splits = split.split(' ')\n",
        "    \n",
        "    word_splits[0] = word_splits[0].capitalize()\n",
        "    \n",
        "    word_splits[-1] = ''.join([word_splits[-1], '.'])\n",
        "\n",
        "    joined = ' '.join(word_splits)\n",
        "\n",
        "    new_splits.append(joined)\n",
        "  \n",
        "  join_split = ' '.join(new_splits)\n",
        "\n",
        "  return join_split\n",
        "\n",
        "def preprocessor(text):\n",
        "\n",
        "  # X = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "  # return tf.one_hot(X, max_id) # for no embedding\n",
        "\n",
        "  # return tokenizer.texts_to_sequences(text) # for embedding\n",
        "\n",
        "def next_word(text, model, temperature=1):\n",
        "  \n",
        "  X_new = preprocessor([text])\n",
        "\n",
        "  y_proba = model.predict(X_new)[0, -1:, :]\n",
        "\n",
        "  rescaled_logits = tf.math.log(y_proba) / temperature\n",
        "\n",
        "  word_id = tf.random.categorical(rescaled_logits, num_samples=1)\n",
        "\n",
        "  return tokenizer.sequences_to_texts(word_id.numpy())[0]\n",
        "\n",
        "def complete_text(text, model, n_words=50, temperature=0.5):\n",
        "\n",
        "  for _ in range(n_words):\n",
        "\n",
        "    space = [' ', next_word(text, model, temperature)]\n",
        "    \n",
        "    text += ''.join(space)\n",
        "\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sITGZHtLZfXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "8ff87c58-0f0b-4561-e57b-b9766655d0b0"
      },
      "source": [
        "key_words = ['fcra', 'loan', 'bank', 'equifax breach', 'credit card', 'credit report']\n",
        "\n",
        "temps = [0.15, 0.2, 0.25]\n",
        "\n",
        "count = 0\n",
        "\n",
        "for key_word in key_words:\n",
        "  for temp in temps:\n",
        "    count += 1\n",
        "    print(f'{count} (kw: \"{key_word}\", tmp: {temp})', text_clean(complete_text(key_word, new_model_2, temperature=temp)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 (kw: \"fcra\", tmp: 0.15) I have been disputing this debt with transunion and i have never received any response from the provider of service. I have been disputing the pmi with the credit bureaus. I have been disputing this account with the credit bureaus.\n",
            "2 (kw: \"fcra\", tmp: 0.2) I have been disputing this account with bsi financial services. I have been disputing this account with my credit report. I have been disputing this debt with the credit bureaus. I have been disputing this debt from my credit report.\n",
            "3 (kw: \"fcra\", tmp: 0.25) I have contacted them about the process of the phone with the company and that my credit score is now. I have been trying to obtain a home and they have not been able to do so. I am not sure what happened to the.\n",
            "4 (kw: \"loan\", tmp: 0.15) I was told that the check was rejected by seterus,. Inc. I was told that the check had bounced. I was told that the check was rejected by the bank of america.\n",
            "5 (kw: \"loan\", tmp: 0.2) I have been a victim of identity theft and i have never received any response from the provider of service. I have been disputing this debt with my credit report. I have been disputing this debt with the credit bureaus.\n",
            "6 (kw: \"loan\", tmp: 0.25) I was told that i was a victim of identity theft. I have been disputing this account with my credit report. I have been disputing this debt on my credit report and i have never received a response from the company.\n",
            "7 (kw: \"bank\", tmp: 0.15) I was told that the check was rejected by the bank of america. I was told that the check had bounced. I was told that the check was not mine.\n",
            "8 (kw: \"bank\", tmp: 0.2) I was told that the check was rejected by the bank of america. I was told that the payment was rejected by the bank of america. I was told that the check was accepted and i was told that the check was rejected.\n",
            "9 (kw: \"bank\", tmp: 0.25) I was told that the check was rejected by the bank of america. I was told that the check was rejected by the bank of america preferred line and i was told that the check was rejected.\n",
            "10 (kw: \"equifax breach\", tmp: 0.15) I am requesting immediate removal of the debt. I have been disputing this account with my credit report and i have been disputing this debt. I have been disputing this account with transunion.\n",
            "11 (kw: \"equifax breach\", tmp: 0.2) I have been disputing this account with my credit report. I have been disputing this account with the credit bureaus. I have been disputing this debt from my credit report.\n",
            "12 (kw: \"equifax breach\", tmp: 0.25) I have been disputing the pmi with the company that i am not able to obtain a new credit card holder. I have never received any communication from the company. I have been disputing the pmi with.\n",
            "13 (kw: \"credit card\", tmp: 0.15) But he was going to collect a debt. I was told that the check was rejected by the bank. I was told that the check was rejected by the bank. I was told that the check was rejected by the bank of america.\n",
            "14 (kw: \"credit card\", tmp: 0.2) I have been disputing the pmi. I have been disputing this account with. I have never received anything from the company. I have no idea what i can do with this company.\n",
            "15 (kw: \"credit card\", tmp: 0.25) I have been trying to get a letter from the company. I have never been able to get a response from them. I have been disputing this account with my credit report.\n",
            "16 (kw: \"credit report\", tmp: 0.15) I have been disputing the pmi. I have been disputing this account with the credit bureaus. I have been disputing this debt from my credit report. I have never been able to obtain a new credit report.\n",
            "17 (kw: \"credit report\", tmp: 0.2) I have never received any response from the provider of service. I have been disputing the pmi with the company and they have refused to remove this account.\n",
            "18 (kw: \"credit report\", tmp: 0.25) I have been disputing this account with them. I have been disputing the pmi. I have been trying to resolve this issue with the company to remove this account. I have been trying to resolve this issue.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}